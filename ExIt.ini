[GLOBAL]
board_size = 5
num_threads = 6
chunksize = 50
dataset_size = 1000
log_dir = logs

[ExpertIteration]
dataset_size = 30000
iterations = 3
active_simulations = 1024

[Training]
max_epochs = 100
batch_size = 256
validation_split = 0.1
patience = 3
model_file = model.h5
history_file = history.pickle

[DatasetTuning]
num_splits = 5
testset_size = 10000
dir = DatasetTuning/{board_size}x{board_size}
model_dir = models/{split_size}_samples
test_data_file = test_data.npz
test_label_file = test_labels.npz
result_file = accuarcy.json
plot_file = DatasetTuning.jpg

[MCTSAgent]
search_depth = 1000

[NMCTSAgent]
search_depth = 500

[expertEval]
num_matches = 75
active_simulations = 64
depth_eval_file = logs/expert_eval_depth({board_size}x{board_size}).json
iter_eval_file = logs/expert_eval_iter({board_size}x{board_size}).json
model_file = model.h5
depth_plot_file = logs/expert_score_depth.jpg
iter_plot_file = logs/expert_score_iter.jpg

[nnEval]
training_file = data({board_size}x{board_size}).npz
label_file = labels({board_size}x{board_size}).npz

[mctsEval]
eval_file = logs/mcts_eval({board_size}x{board_size}).json
plot_file = logs/mcts_score.jpg

[apprenticeEval]
active_simulations = 64
eval_file = logs/apprentice_eval({board_size}x{board_size}).json
prediction_data = data.npz
prediction_labels = labels.npz
plot_file = logs/apprentice_score.jpg

[TrueSkill]
initial_mu = 1200
initial_sigma = 200
beta = 100
tau = 2
draw_probability = 0.01